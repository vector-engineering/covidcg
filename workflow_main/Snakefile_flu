# coding: utf-8

"""Main data processing workflow from ingested data

$ snakemake -s Snakefile_flu --configfile ../config/config_flu_genbank.yaml -j6

This DAG building gets kind of complicated...
First, sequences are split up by submission date and subtype (this is
done in the ingest step(s)).
Then, we need to align each sequence all references within its respective
subtype, and not to references from other subtypes.
Additionally, alignments to each reference within the subtype has to be done
separately.

Working backwards, we combine reference alignments per subtype-chunk at the
combine_alignments step. The get_alignments() input function defines what
references are used for each subtype-chunk -- and references per subtype
are scraped into the SUBTYPE_REFS dictionary.

combine_alignments() subsequently triggers an align_sequences job for each
subtype-chunk and matching reference (1 or more references per subtype)

After this alignment mess, we can proceed with extract_dna_mutations, etc.
normally with one file per subtype-chunk.

Author: Albert Chen - Vector Engineering Team (chena@broadinstitute.org)
"""

import datetime
import os
from pathlib import Path

data_folder = os.path.join("..", config["data_folder"])
static_data_folder = os.path.join("..", config["static_data_folder"])

# Get today's date in ISO format (YYYY-MM-DD)
today_str = datetime.date.today().isoformat()

# Find chunks
CHUNKS, = glob_wildcards(os.path.join(
    data_folder, "fasta_raw", "{chunk}.fa.gz"
))

SEGMENTS = config["segments"]
SUBTYPES = [
    d.name for d in sorted(
        (Path(static_data_folder) / 'mut_references').iterdir()
    ) 
    if d.is_dir()
]
# print(SEGMENTS, SUBTYPES)

# Get references for each subtype
SUBTYPE_REFS = {}
for subtype in SUBTYPES:
    SUBTYPE_REFS[subtype] = [
        d.name for d in sorted(
            (Path(static_data_folder) / 'mut_references' / subtype).iterdir()
        ) 
        if d.is_dir()
    ]
# print(SUBTYPE_REFS)

def get_segment(wildcards, output=None):
    return wildcards.chunk.split('_')[0]

def get_subtype(wildcards, output=None):
    return wildcards.chunk.split('_')[1]

def get_alignments(wildcards):
    segment = get_segment(wildcards)
    subtype = get_subtype(wildcards)
    return expand(
        os.path.join(data_folder, "bam_ref", "{ref}_{{chunk}}.bam"),
        ref=SUBTYPE_REFS[subtype], allow_missing=True
    )

def get_reference_file(wildcards):
    segment = get_segment(wildcards)
    subtype = get_subtype(wildcards)
    return os.path.join(static_data_folder, 'mut_references', subtype, "{ref}", segment + '.fa')

def get_combined_reference_file(wildcards, output=None):
    segment = get_segment(wildcards, output)
    subtype = get_subtype(wildcards, output)
    return os.path.join(static_data_folder, 'combined_mut_references', subtype, segment + '.fa')

wildcard_constraints:
    chunk="[0-9]+_[A-Za-z0-9-]+_[0-9-]+"

rule all:
    input:
        expand(
            os.path.join(static_data_folder, "combined_mut_references", "{subtype}", "{segment}.fa"),
            subtype=SUBTYPES, segment=SEGMENTS
        ),
        os.path.join(static_data_folder, "reference.json"),
        # combined_dna_mutations = os.path.join(data_folder, 'dna_mutations.csv')
        # case_data = os.path.join(data_folder, "case_data.json")
        expand(os.path.join(data_folder, "dna_mutation", "{chunk}_dna_mutation.csv"), chunk=CHUNKS),
        expand(os.path.join(data_folder, "gene_aa_mutation", "{chunk}_gene_aa_mutation.csv"), chunk=CHUNKS)


rule process_genes_and_proteins:
    """Calculate some additional columns on top of the human-generated
    genes.json and proteins.json annotations file
    """
    input:
        genes = os.path.join(static_data_folder, "genes.json"),
        proteins = os.path.join(static_data_folder, "proteins.json")
    output:
        genes = os.path.join(static_data_folder, "genes_processed.json"),
        proteins = os.path.join(static_data_folder, "proteins_processed.json")
    shell:
        """
        python3 scripts/gene_protein_defs.py -i {input.genes} -o {output.genes}
        python3 scripts/gene_protein_defs.py -i {input.proteins} -o {output.proteins}
        """


rule combine_references:
    params:
        ref_seq = os.path.join(static_data_folder, "mut_references", "{subtype}", "**", "{segment}.fa")
    output:
        ref_seq = os.path.join(static_data_folder, "combined_mut_references", "{subtype}", "{segment}.fa")
    shell:
        """
        # Insert newlines in between each file
        for f in {params.ref_seq}; do (cat $f; echo '') >> {output.ref_seq}; done
        """


rule write_reference_files:
    """Write some of the reference sequence data as JSON
    files that can be easily loaded by the front-end
    """
    input:
        primers = os.path.join(static_data_folder, "primers.csv")
    params:
        reference_path = os.path.join(static_data_folder, "mut_references"),
        subtypes = SUBTYPES,
        segments = SEGMENTS
    output:
        # Write data to JSON for the JS/UI to handle
        reference = os.path.join(static_data_folder, "reference.json"),
        primers = os.path.join(static_data_folder, "primers.json")
    shell:
        """
        python3 scripts/write_reference_files.py \
            --reference-path {params.reference_path} \
            --subtypes {params.subtypes} \
            --segments {params.segments} \
            --primers-csv {input.primers} \
            --reference-json {output.reference} \
            --primers-json {output.primers}
        """


rule preprocess_sequences:
    """Filter out sequences...
    """
    input:
        fasta = os.path.join(data_folder, "fasta_raw", "{chunk}.fa.gz")
    output:
        fasta = os.path.join(data_folder, "fasta_processed", "{chunk}.fa.gz")
    shell:
        """
        # Pass-through for now
        cp {input.fasta} {output.fasta}
        """

rule align_sequences:
    input:
        fasta = rules.preprocess_sequences.output.fasta,
        ref_seq = get_reference_file
    output:
        bam = os.path.join(data_folder, "bam_ref", "{ref}_{chunk}.bam")
    shell:
        """
        minimap2 -a --eqx --MD -Q --score-N 0 --sam-hit-only {input.ref_seq} {input.fasta} | samtools view -b > {output.bam}
        """


rule combine_alignments:
    input: get_alignments
    output:
        bam = os.path.join(data_folder, "bam", "{chunk}.bam")
    shell:
        """
        samtools merge -o {output.bam} {input}
        """


rule extract_dna_mutations:
    """Find mutations on the NT level for each sequence
    """
    input:
        bam = rules.combine_alignments.output.bam,
        reference = get_combined_reference_file
    output:
        dna_mutation = os.path.join(data_folder, "dna_mutation", "{chunk}_dna_mutation.csv")
    shell:
        """
        python3 scripts/extract_dna_mutations.py \
            --bam {input.bam} \
            --reference {input.reference} \
            --out {output.dna_mutation}
        """

rule extract_aa_mutations:
    """Using the NT mutations, translate genes/proteins and find mutations
    on the AA level, for genes
    """
    input:
        dna_mutation = rules.extract_dna_mutations.output.dna_mutation,
        genes_file = rules.process_genes_and_proteins.output.genes,
        proteins_file = rules.process_genes_and_proteins.output.proteins,
        reference = rules.write_reference_files.output.reference
    params:
        segment = get_segment,
        subtype = get_subtype
    output:
        gene_aa_mutation = os.path.join(
            data_folder, "gene_aa_mutation", "{chunk}_gene_aa_mutation.csv"
        ),
        protein_aa_mutation = os.path.join(
            data_folder, "protein_aa_mutation", "{chunk}_protein_aa_mutation.csv"
        )
    shell:
        """
        python3 scripts/extract_aa_mutations.py \
            --dna-mutation {input.dna_mutation} \
            --gene-protein-def {input.genes_file} \
            --reference {input.reference} \
            --segment {params.segment} \
            --subtype {params.subtype} \
            --mode gene \
            --out {output.gene_aa_mutation}

        python3 scripts/extract_aa_mutations.py \
            --dna-mutation {input.dna_mutation} \
            --gene-protein-def {input.proteins_file} \
            --reference {input.reference} \
            --segment {params.segment} \
            --subtype {params.subtype} \
            --mode protein \
            --out {output.protein_aa_mutation}
        """


# rule combine_all_data:
#     """Main rule for generating the data files for the browser
#     Mostly just a bunch of joins
#     """
#     input:
#         processed_fasta_files = os.path.join(data_folder, "fasta_processed"),
#         metadata = os.path.join(data_folder, "metadata+subtype.csv"),
#         dna_mutation_files = expand(
#             os.path.join(data_folder, "dna_mutation", "{chunk}_dna_mutation.csv"),
#             chunk=CHUNKS
#         ),
#         gene_aa_mutation_files = expand(
#             os.path.join(data_folder, "gene_aa_mutation", "{chunk}_gene_aa_mutation.csv"),
#             chunk=CHUNKS
#         ),
#         protein_aa_mutation_files = expand(
#             os.path.join(data_folder, "protein_aa_mutation", "{chunk}_protein_aa_mutation.csv"),
#             chunk=CHUNKS
#         )
#     output:
#         metadata_map = os.path.join(data_folder, "metadata_map.json"),
#         # Only used to build the location tree
#         case_data = os.path.join(data_folder, "case_data.json"),
#         case_data_csv = os.path.join(data_folder, "case_data.csv")
#     params:
#         count_threshold=config["mutation_count_threshold"],
#         group_cols=list(config["group_cols"].keys()),
#         metadata_cols=list(config["metadata_cols"].keys())
#     shell:
#         """
#         python3 scripts/combine_all_data.py \
#             --fasta {input.processed_fasta_files} \
#             --metadata {input.metadata} \
#             --dna-mutation-files {input.dna_mutation_files} \
#             --gene-aa-mutation-files {input.gene_aa_mutation_files} \
#             --protein-aa-mutation-files {input.protein_aa_mutation_files} \
#             --metadata-map {output.metadata_map} \
#             --case-data {output.case_data} \
#             --case-data-csv {output.case_data_csv} \
#             --count-threshold {params.count_threshold} \
#             --metadata-cols {params.metadata_cols}

#             # --group-cols {params.group_cols}
#         """
