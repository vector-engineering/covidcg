# coding: utf-8

"""Main data processing workflow from ingested data

$ snakemake -s Snakefile_rsv --configfile ../config/config_rsv_genbank.yaml -j6

Author: Albert Chen - Vector Engineering Team (chena@broadinstitute.org)
"""

import datetime
import os

data_folder = os.path.join("..", config["data_folder"])
static_data_folder = os.path.join("..", config["static_data_folder"])

# Get today's date in ISO format (YYYY-MM-DD)
today_str = datetime.date.today().isoformat()

# Find chunks
CHUNKS, = glob_wildcards(os.path.join(
    data_folder, "fasta_raw", "{chunk}.fa.gz"
))

REFS, = glob_wildcards(os.path.join(
    static_data_folder, "mut_references", "{ref}.fa"
))

# Additional analyses module
include: "analyses/Snakefile_rsv"

wildcard_constraints:
    chunk="[AB]_[0-9]{4}-[0-9]{2}"

rule all:
    input:
        # Generate reference-related data
        os.path.join(static_data_folder, "reference.json"),
        os.path.join(static_data_folder, "primers.json"),
        # Packaged data
        os.path.join(data_folder, 'data_complete.csv'),
        # Additional analyses
        # rules.additional_analyses.output.done
        # Surveillance data
        rules.surveillance_data.output.group_counts,
        rules.surveillance_data.output.group_regression,
        # Global sequencing data
        rules.global_seq_data.output.case_count,
        rules.global_seq_data.output.sequences_per_month,
        rules.global_seq_data.output.turnaround_per_month,
        rules.global_seq_data.output.iso_lookup,
        

rule process_genes_and_proteins:
    """Calculate some additional columns on top of the human-generated
    genes.json and proteins.json annotations file
    """
    input:
        genes = os.path.join(static_data_folder, "genes.json"),
        proteins = os.path.join(static_data_folder, "proteins.json")
    output:
        genes = os.path.join(static_data_folder, "genes_processed.json"),
        proteins = os.path.join(static_data_folder, "proteins_processed.json")
    shell:
        """
        python3 scripts/gene_protein_defs.py -i {input.genes} -o {output.genes}
        python3 scripts/gene_protein_defs.py -i {input.proteins} -o {output.proteins}
        """


rule combine_references:
    input:
        ref_seq = expand(os.path.join(static_data_folder, "mut_references", "{ref}.fa"), ref=REFS)
    output:
        ref_seqs = os.path.join(static_data_folder, "reference.fa")
    shell:
        """
        cat {input.ref_seq} > {output.ref_seqs}
        """


rule write_reference_files:
    """Write some of the reference sequence data as JSON
    files that can be easily loaded by the front-end
    """
    input:
        reference = os.path.join(static_data_folder, "reference.fa"),
        primers = os.path.join(static_data_folder, "primers.csv")
    output:
        # Write data to JSON for the JS/UI to handle
        reference = os.path.join(static_data_folder, "reference.json"),
        primers = os.path.join(static_data_folder, "primers.json")
    shell:
        """
        python3 scripts/write_reference_files.py \
            --reference-fasta {input.reference} \
            --primers-csv {input.primers} \
            --reference-json {output.reference} \
            --primers-json {output.primers}
        """


rule preprocess_sequences:
    """Filter out sequences...
    """
    input:
        fasta = os.path.join(data_folder, "fasta_raw", "{chunk}.fa.gz")
    output:
        fasta = os.path.join(data_folder, "fasta_processed", "{chunk}.fa.gz")
    shell:
        """
        # Pass-through for now
        cp {input.fasta} {output.fasta}
        """

rule align_sequences:
    input:
        fasta = rules.preprocess_sequences.output.fasta,
        ref_seq = os.path.join(static_data_folder, "mut_references", "{ref}.fa")
    output:
        bam = os.path.join(data_folder, "bam_ref", "{ref}_{chunk}.bam")
    shell:
        """
        minimap2 -a --eqx --MD -Q --score-N 0 --sam-hit-only {input.ref_seq} {input.fasta} | samtools view -b > {output.bam}
        """

rule combine_alignments:
    input: 
        bam = expand(
            os.path.join(data_folder, "bam_ref", "{ref}_{chunk}.bam"),
            ref=REFS,
            allow_missing=True
        )
    output:
        bam = os.path.join(data_folder, "bam", "{chunk}.bam")
    shell:
        """
        samtools merge -o {output.bam} {input.bam}
        """

rule extract_dna_mutations:
    """Find mutations on the NT level for each sequence
    """
    input:
        bam = rules.combine_alignments.output.bam,
        reference = rules.write_reference_files.output.reference
    output:
        dna_mutation = os.path.join(data_folder, "dna_mutation", "{chunk}_dna_mutation.csv")
    shell:
        """
        python3 scripts/extract_dna_mutations.py \
            --bam {input.bam} \
            --reference {input.reference} \
            --out {output.dna_mutation}
        """

rule extract_aa_mutations:
    """Using the NT mutations, translate genes/proteins and find mutations
    on the AA level, for genes
    """
    input:
        dna_mutation = rules.extract_dna_mutations.output.dna_mutation,
        genes_file = rules.process_genes_and_proteins.output.genes,
        proteins_file = rules.process_genes_and_proteins.output.proteins,
        reference = rules.write_reference_files.output.reference
    output:
        gene_aa_mutation = os.path.join(
            data_folder, "gene_aa_mutation", "{chunk}_gene_aa_mutation.csv"
        ),
        protein_aa_mutation = os.path.join(
            data_folder, "protein_aa_mutation", "{chunk}_protein_aa_mutation.csv"
        )
    shell:
        """
        python3 scripts/extract_aa_mutations.py \
            --dna-mutation {input.dna_mutation} \
            --gene-protein-def {input.genes_file} \
            --reference {input.reference} \
            --segment 1 \
            --mode gene \
            --out {output.gene_aa_mutation}

        python3 scripts/extract_aa_mutations.py \
            --dna-mutation {input.dna_mutation} \
            --gene-protein-def {input.proteins_file} \
            --reference {input.reference} \
            --segment 1 \
            --mode protein \
            --out {output.protein_aa_mutation}
        """


rule combine_all_data:
    """Main rule for generating the data files for the browser
    Mostly just a bunch of joins
    """
    input:
        metadata = os.path.join(data_folder, "metadata+subtype.csv"),
        dna_mutation_files = expand(
            os.path.join(data_folder, "dna_mutation", "{chunk}_dna_mutation.csv"),
            chunk=CHUNKS
        ),
        gene_aa_mutation_files = expand(
            os.path.join(data_folder, "gene_aa_mutation", "{chunk}_gene_aa_mutation.csv"),
            chunk=CHUNKS
        ),
        protein_aa_mutation_files = expand(
            os.path.join(data_folder, "protein_aa_mutation", "{chunk}_protein_aa_mutation.csv"),
            chunk=CHUNKS
        ),
        ref_seqs_json = rules.write_reference_files.output.reference
    output:
        metadata_map = os.path.join(data_folder, "metadata_map.json"),
        # Only used to build the location tree
        case_data = os.path.join(data_folder, "case_data.json"),
        case_data_csv = os.path.join(data_folder, "case_data.csv")
    params:
        processed_fasta_files = os.path.join(data_folder, "fasta_processed"),
        count_threshold = config["mutation_count_threshold"],
        group_cols = list(config["group_cols"].keys()),
        metadata_cols = list(config["metadata_cols"].keys())
    shell:
        """
        python3 scripts/combine_all_data.py \
            --fasta {params.processed_fasta_files} \
            --metadata {input.metadata} \
            --reference-json {input.ref_seqs_json} \
            --dna-mutation-files {input.dna_mutation_files} \
            --gene-aa-mutation-files {input.gene_aa_mutation_files} \
            --protein-aa-mutation-files {input.protein_aa_mutation_files} \
            --metadata-map {output.metadata_map} \
            --case-data {output.case_data} \
            --case-data-csv {output.case_data_csv} \
            --count-threshold {params.count_threshold} \
            --metadata-cols {params.metadata_cols}

            # --group-cols {params.group_cols}
        """


rule build_location_tree:
    input:
        case_data = rules.combine_all_data.output.case_data,
        metadata_map = rules.combine_all_data.output.metadata_map,
        emoji_map_file = os.path.join(
            static_data_folder, "country_to_emoji.xls"
        )
    output:
        geo_select_tree = os.path.join(data_folder, "geo_select_tree.json")
    shell:
        """
        python3 scripts/build_location_tree.py \
            --case-data {input.case_data} \
            --metadata-map {input.metadata_map} \
            --emoji-map {input.emoji_map_file} \
            --out {output.geo_select_tree}
        """


rule global_group_counts:
    """Get the number of sequences in each group
    Doing this in the pipeline just saves some work for the browser later
    """
    input:
        case_data = rules.combine_all_data.output.case_data,
        ref_seqs_json = rules.write_reference_files.output.reference
    output:
        global_group_counts = os.path.join(
            data_folder, "global_group_counts.json"
        )
    params:
        group_cols = list(config["group_cols"].keys())
    shell:
        """
        python3 scripts/global_group_counts.py \
            --case-data {input.case_data} \
            --reference-json {input.ref_seqs_json} \
            --out-global-group-counts {output.global_group_counts} \
            --group-cols {params.group_cols}
        """

rule build_full_dataframe:
    input:
        case_data = rules.combine_all_data.output.case_data,
        metadata_map = rules.combine_all_data.output.metadata_map
    output:
        full_df = os.path.join(data_folder, 'data_complete.csv')
    shell:
        """
        python3 scripts/build_full_dataframe.py \
            --case-data {input.case_data} \
            --metadata-map {input.metadata_map} \
            --df-out {output.full_df}
        """